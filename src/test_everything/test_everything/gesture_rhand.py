import rclpy
from rclpy.node import Node

from sensor_msgs.msg import Image
from std_msgs.msg import String
from cv_bridge import CvBridge
import cv2
import mediapipe as mp
import numpy as np

from .gesture_two import GestureAnalyzer   # âœ… æ–°çš„ç»Ÿä¸€æ¨¡å‹ï¼ˆè¾“å…¥ä¸º holisticï¼‰

class GestureRecognizerNode(Node):
    def __init__(self):
        super().__init__('gesture_recognizer_node')

        # è®¢é˜…æ‘„åƒå¤´å›¾åƒ
        self.rgb_sub = self.create_subscription(Image, '/camera/color/image_raw', self.main_callback, 10)

        # å‘å¸ƒè¯†åˆ«ç»“æœ
        self.publisher = self.create_publisher(String, '/gesture_result', 10)

        # åˆå§‹åŒ–è¯†åˆ«å™¨ï¼ˆç»Ÿä¸€ç‰ˆæœ¬ï¼‰
        self.recognizer = GestureAnalyzer(w=1280, h=720)

        self.bridge = CvBridge()

        # åˆå§‹åŒ– Mediapipe Holistic
        self.mp_holistic = mp.solutions.holistic
        self.detector = self.mp_holistic.Holistic(
            static_image_mode=False,
            model_complexity=2,
            smooth_landmarks=True,
            enable_segmentation=False,
            refine_face_landmarks=True,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        self.mp_drawing = mp.solutions.drawing_utils
        self.mp_drawing_styles = mp.solutions.drawing_styles

    # --------------------------------------------------------
    def main_callback(self, msg):
        img = self.bridge.imgmsg_to_cv2(msg, 'bgr8')

        # 1ï¸âƒ£ Mediapipe Holistic å¤„ç†
        results_holistic = self.detector.process(img)

        # 2ï¸âƒ£ æ‰‹åŠ¿è¯†åˆ«ï¼ˆç›´æ¥è¿”å›ç»“æœå­—å…¸ï¼‰
        gesture_dict = self.recognizer.update(results_holistic)

        # 3ï¸âƒ£ è¯»å–è¯†åˆ«ç»“æœï¼ˆå®‰å…¨æ£€æŸ¥ï¼‰
        if not gesture_dict:
            gesture_name = "none"
        else:
            detected = [k for k, v in gesture_dict.items() if v]
            gesture_name = detected[0] if detected else "none"

        print(gesture_dict)

        # 4ï¸âƒ£ å‘å¸ƒ ROS ç»“æœ
        out_msg = String()
        out_msg.data = gesture_name
        self.publisher.publish(out_msg)

        # 5ï¸âƒ£ æ—¥å¿—æ‰“å°
        if gesture_name != "none":
            self.get_logger().info(f"ğŸ¤– Detected gesture: {gesture_name}")

        # 6ï¸âƒ£ å¯è§†åŒ–ï¼ˆä»ç„¶ç”¨ results_holisticï¼Œè€Œä¸æ˜¯ dictï¼‰
        self._draw_result(img, results_holistic, gesture_name)

    # --------------------------------------------------------
    def _draw_result(self, frame, results, gesture_name):
        """åœ¨å›¾åƒä¸Šç»˜åˆ¶éª¨æ¶å’Œæ‰‹åŠ¿æ–‡å­—"""
        # ç»˜åˆ¶ pose
        if results.pose_landmarks:
            self.mp_drawing.draw_landmarks(
                frame,
                results.pose_landmarks,
                self.mp_holistic.POSE_CONNECTIONS,
                landmark_drawing_spec=self.mp_drawing_styles.get_default_pose_landmarks_style()
            )

        # ç»˜åˆ¶ hand
        if results.left_hand_landmarks:
            self.mp_drawing.draw_landmarks(
                frame,
                results.left_hand_landmarks,
                self.mp_holistic.HAND_CONNECTIONS,
                landmark_drawing_spec=self.mp_drawing_styles.get_default_hand_landmarks_style()
            )
        if results.right_hand_landmarks:
            self.mp_drawing.draw_landmarks(
                frame,
                results.right_hand_landmarks,
                self.mp_holistic.HAND_CONNECTIONS,
                landmark_drawing_spec=self.mp_drawing_styles.get_default_hand_landmarks_style()
            )

        # ç»˜åˆ¶å½“å‰æ‰‹åŠ¿æ–‡å­—
        if gesture_name != "none":
            cv2.putText(frame, f"Gesture: {gesture_name}",
                        (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)

        cv2.imshow("Gesture Recognition", frame)
        cv2.waitKey(1)

# --------------------------------------------------------
def main():
    rclpy.init()
    node = GestureRecognizerNode()
    rclpy.spin(node)
    node.destroy_node()
    rclpy.shutdown()

if __name__ == "__main__":
    main()
